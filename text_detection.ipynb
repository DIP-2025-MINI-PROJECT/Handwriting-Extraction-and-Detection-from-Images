import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ReduceLROnPlateau # For high accuracy
import numpy as np
import scipy.io as sio
import os
import matplotlib.pyplot as plt

# Imports for plotting and advanced metrics
from sklearn.metrics import roc_curve, auc, confusion_matrix
from itertools import cycle

print("Loading .mat file from Kaggle dataset...")
mat_file_path = "/kaggle/input/emnist-byclass-mat/emnist-byclass.mat"

if not os.path.exists(mat_file_path):
  print("="*50)
  print("ERROR: Dataset not found.")
  print("Please make sure you have added the 'EMNIST dataset in .mat format' to this notebook.")
  print("="*50)
else:
  mat = sio.loadmat(mat_file_path)

  # Load training data
  x_train = mat['dataset']['train'][0,0]['images'][0,0]
  y_train_labels = mat['dataset']['train'][0,0]['labels'][0,0] # Store labels for AUC

  # Load test data
  x_test = mat['dataset']['test'][0,0]['images'][0,0]
  y_test_labels = mat['dataset']['test'][0,0]['labels'][0,0] # Store labels for AUC

  
  print("Preprocessing data...")
  # 1. Reshape and Transpose (Just like in MATLAB)
  x_train = x_train.reshape((-1, 28, 28)).transpose((0, 2, 1))
  x_test = x_test.reshape((-1, 28, 28)).transpose((0, 2, 1))

  # 2. Add the "channels" dimension
  x_train = np.expand_dims(x_train, axis=-1)
  x_test = np.expand_dims(x_test, axis=-1)

  # 3. NORMALIZE THE DATA
  print("Applying normalization...")
  x_train = x_train.astype('float32') / 255.0
  x_test = x_test.astype('float32') / 255.0

  # 4. Convert labels to categorical (one-hot encoding)
  num_classes = 62
  y_train_one_hot = keras.utils.to_categorical(y_train_labels, num_classes)
  y_test_one_hot = keras.utils.to_categorical(y_test_labels, num_classes)

  print(f"Training data shape: {x_train.shape}")
  print(f"Test data shape: {x_test.shape}")
  print("Using 100% of the data for maximum accuracy.")

  metrics_to_track = [
      'accuracy',
      tf.keras.metrics.AUC(name='auc')
  ]

  print("Building model...")
  input_shape = (28, 28, 1) # height, width, channels

  model = keras.Sequential(
      [
          layers.Input(shape=input_shape),
          layers.Conv2D(32, kernel_size=(3, 3), padding='same'),
          layers.BatchNormalization(),
          layers.ReLU(),
          layers.Conv2D(32, kernel_size=(3, 3), padding='same'),
          layers.BatchNormalization(),
          layers.ReLU(),
          layers.MaxPooling2D(pool_size=(2, 2), strides=2),
          layers.Dropout(0.25),
          layers.Conv2D(64, kernel_size=(3, 3), padding='same'),
          layers.BatchNormalization(),
          layers.ReLU(),
          layers.Conv2D(64, kernel_size=(3, 3), padding='same'),
          layers.BatchNormalization(),
          layers.ReLU(),
          layers.MaxPooling2D(pool_size=(2, 2), strides=2),
          layers.Dropout(0.25),
          layers.Flatten(),
          layers.Dense(512),
          layers.BatchNormalization(),
          layers.ReLU(),
          layers.Dropout(0.5),
          layers.Dense(num_classes, activation="softmax"),
      ]
  )

  # --- Build the data augmentation ---
  data_augmentation = keras.Sequential([
      layers.RandomRotation(factor=(-0.02, 0.02)), # +/- 8 degrees
      layers.RandomTranslation(height_factor=0.07, width_factor=0.07), # +/- 2 pixels
      layers.RandomZoom(height_factor=(-0.1, 0.1)) # +/- 10%
  ])

  # --- Build the final trainable model ---
  train_model = keras.Sequential([
      layers.Input(shape=input_shape),
      data_augmentation, # Augmentation is applied FIRST
      model              # Then the data flows into the model
  ])

  model.compile(
      loss="categorical_crossentropy", 
      optimizer="adam", 
      metrics=metrics_to_track
  )
  train_model.compile(
      loss="categorical_crossentropy", 
      optimizer="adam", 
      metrics=metrics_to_track
  )
    
  model.summary()


  


  early_stopping = keras.callbacks.EarlyStopping(
      monitor='val_accuracy', 
      patience=5,  # Increased from 3 to 5
      restore_best_weights=True
  )


  reduce_lr = ReduceLROnPlateau(
      monitor='val_loss', 
      factor=0.2,   # Reduce LR by 80% (0.2)
      patience=2,   # Wait 2 epochs of no improvement
      min_lr=1e-6,  # Don't go below this learning rate
      verbose=1     # Print a message when LR is reduced
  )

  batch_size = 128  # Safe and effective batch size
  epochs = 30 

  print(f"Using batch size: {batch_size}")

  history = train_model.fit(
      x_train, y_train_one_hot,
      batch_size=batch_size,
      epochs=epochs,
      validation_data=(x_test, y_test_one_hot),
      # --- Pass in both callbacks ---
      callbacks=[early_stopping, reduce_lr] 
  )

  print("\n\n--- Training Complete ---")

 
  print("Plotting Training vs. Validation curves...")
  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))

  # Plot training & validation accuracy values
  ax1.plot(history.history['accuracy'])
  ax1.plot(history.history['val_accuracy'])
  ax1.set_title('Model Accuracy')
  ax1.set_ylabel('Accuracy')
  ax1.set_xlabel('Epoch')
  ax1.legend(['Train', 'Validation'], loc='upper left')

  # Plot training & validation loss values
  ax2.plot(history.history['loss'])
  ax2.plot(history.history['val_loss'])
  ax2.set_title('Model Loss')
  ax2.set_ylabel('Loss')
  ax2.set_xlabel('Epoch')
  ax2.legend(['Train', 'Validation'], loc='upper left')

  plt.tight_layout()
  plt.show()
